[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Building composite indicators with {composer}",
    "section": "",
    "text": "1 Welcome\nWelcome to the documentation for the {composer} app. The {composer} app provides an easy interface for building composite indicators using any data set. Users can visualise and explore results in depth, and download figures and reports.\n{composer} is a Shiny app which is wrapped in an R package. At the moment, in order to run the app you will have to have R installed, then first install the package:\n# install package if not already installed\nremotes::install_github(\"finddx/composer\")\nTo run the app you then have to run:\n# load package\nlibrary(composer)\n\n# run app\nrun_gui()\nAs a Shiny app, the app will open in your web browser and acts as an interactive GUI.\nThe rest of this page gives some general information about the app and composite indicators. If you want to get started quickly, go straight to Chapter 2. Detailed documentation on each tab of the app starts at Chapter 4."
  },
  {
    "objectID": "index.html#composite-indicators",
    "href": "index.html#composite-indicators",
    "title": "Building composite indicators with {composer}",
    "section": "1.1 Composite indicators",
    "text": "1.1 Composite indicators\nIndicators are used in many contexts to measure complex multidimensional concepts, typically with the aim of prioritising resources and interventions, and also to track progress. In the international/policy context, indicators are often used to compare countries and/or sub-national regions. Examples include the Human Development Index, the Global Innovation Index, and many others.\nQuite often, the concept to be measured cannot be sufficiently captured with one indicator, and a group of indicators is needed. As the number of indicators gets larger, it becomes increasingly difficult to compare and prioritise.\nComposite indicators are mathematical aggregations of a set of indicators into a single measure. Indicators are organised into conceptual groups which aim to follow a map of the concept to be measured. Aggregating the indicators into a single composite indicator allows quick and easy comparisons, clear communication with stakeholders, and acts as a natural entry point to the data set underneath.\nImportantly, in building a composite indicator, we do not wish to substitute the underlying data, but rather to complement it with an overview measure. Composite indicators involve a number of subjective decisions in their construction, and cannot fully capture all information in the indicator set underneath. However, used carefully, they are a valuable addition and entry point to a complex data set."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Building composite indicators with {composer}",
    "section": "1.2 Features",
    "text": "1.2 Features\nThe {composer} app includes the following features:\n\nAny number of indicators and units and aggregation levels\nUnit screening by data availability\nMissing data imputation\nOutlier treatment\nNormalisation using various methods\nWeighted aggregation\nInteractive maps (if the units are countries)\nDetailed analysis of indicators using bubble charts, bar charts\nStatistical analysis using visualisation of distributions, correlation plots\nDownloadable unit profiles\nInteractive reweighting\nSensitivity analysis on assumptions, checking the effects of removing indicators and indicator groups"
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "Building composite indicators with {composer}",
    "section": "1.3 Methodology",
    "text": "1.3 Methodology\nThe composite indicator methodology used in this app follows the internationally-recognised OECD/JRC Handbook of Composite Indicators, and the methodology used by the European Commission. If you wish to learn more about building and analysing composite indicators, see for example the recent training course given by the European Commission, including videos and slides.\nMost of the data processing in the app is done using the COINr package, which is an R package for building and analysing composite indicators. R users may wish to additionally work with COINr directly to access functionalities not included in the app."
  },
  {
    "objectID": "index.html#terminology",
    "href": "index.html#terminology",
    "title": "Building composite indicators with {composer}",
    "section": "1.4 Terminology",
    "text": "1.4 Terminology\nThroughout this book we will use the following terms:\n\nUnits are the set of “things” that we want to compare and possibly rank. Often units are countries, but they could also be regions, cities or organisations, which is why we use “units” here.\nIndicators are measured variables which we use to compare units.\nA composite indicator is a mathematical aggregation of a set of indicators into one composite measure, which aims to summarise the indicator set as well as possible."
  },
  {
    "objectID": "index.html#development-and-contribution",
    "href": "index.html#development-and-contribution",
    "title": "Building composite indicators with {composer}",
    "section": "1.5 Development and contribution",
    "text": "1.5 Development and contribution\n{composer} was developed over 2023-2024 and (at the time of writing in Feb 2024) is in an early release phase. If you find a bug in the app, or have a feature request, please open an issue on GitHub. Collaboration and contribution are welcome: if you wish to contribute please fork the GitHub repo, make any changes and make a pull request. Feel free to discuss on the issues page, or contact us."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Building composite indicators with {composer}",
    "section": "1.6 Acknowledgements",
    "text": "1.6 Acknowledgements\n{composer} was originally built as an internal-use app for the Foundation for Innovative New Diagnostics (FIND), who then kindly granted permission for an open-source release. The app is effectively a front end for the COINr package, and also benefits from many other open-source R packages."
  },
  {
    "objectID": "overview.html#before-you-start",
    "href": "overview.html#before-you-start",
    "title": "2  Overview",
    "section": "2.1 Before you start",
    "text": "2.1 Before you start\nThe {composer} app deals with the numerical data-processing steps in composite indicator construction. Before arriving at this point, it is necessary to have a set of indicators which follow a conceptual framework.\nThe conceptual framework is a map of the concept you want to measure. Typically, the overall concept is broken down into sub-concepts (“dimensions”), which themselves may be broken down into smaller chunks. This results in a hierarchical map of the concept.\n\n\n\nDeconstruction of concept into conceptual framework.\n\n\nAt this point, indicators are assigned to the groups at the lowest level in the conceptual framework (in the figure above this is the sub-dimensions). The aim is that each sub-dimension is well-measured by the group of indicators assigned to it. Then, a score can be calculated for each sub-dimension using a weighted aggregation (e.g. the weighted mean). Scores for dimensions are calculated by aggregating sub-dimension scores, and the index score is calculated by aggregating the dimension scores. The conceptual framework therefore maps the deconstruction of the concept and also its mathematical reconstruction via the indicator framework.\n\n\n\nReconstruction of concept with indicators and aggregation.\n\n\nThis approach can result in a conceptual framework with any number of indicators and levels, but simplicity should be preferred where possible.\nTypically the conceptual framework is constructed by consulting experts, and performing a literature review. If you yourself are an expert in the topic, you may be able to map the concept sufficiently well on your own. A more detailed explanation of building a conceptual framework can be found here.\nAfter the conceptual framework, indicators are selected. You should aim to have enough indicators to sufficiently capture the concept to be measured, but avoid redundancies and overlaps as much as possible. Evaluate each indicator critically based on its relevance, value added, reliability, data availability and other criteria. Don’t automatically include indicators simply because data is available. Some more guidance on indicator selection can be found here.\nFor each indicator, collect as much available data as possible. If possible, use a reproducible workflow to clean and process each indicator, so that there is a clear record of how the indicator arrived in its present state. This can be invaluable when later on stakeholders may ask questions about the methodology behind indicators, and also helps to spot errors. If your data is measuring attributes of countries, use ISO alpha-3 country codes - this allows the app to translate your data onto maps, and is anyway good practice for merging data.\nGeneral guidance on composite indicators can be found at the European Commission’s Competence Centre for Composite Indicators."
  },
  {
    "objectID": "overview.html#data-input",
    "href": "overview.html#data-input",
    "title": "2  Overview",
    "section": "2.2 Data input",
    "text": "2.2 Data input\nThe next step is to enter your data into the app. To do this, you have to compose your data set and conceptual framework into a single spreadsheet containing the formatted input tables required by the {composer} app. This step needs to be done carefully and is explained in more detail in Chapter 4.\nThe app will attempt to spot any errors in your input data and give helpful error messages where possible. However, it is important to carefully read the instructions on input data formatting.\nOnce the data is correctly formatted, upload your data to the app. If successful, the app will return a summary of the input data, as well as visual plot of the conceptual framework.\n\n\n\nExample framework plot\n\n\nThe framework plot should reflect the expected index structure. The above figure is from our example data set which will be discussed in Chapter 4."
  },
  {
    "objectID": "overview.html#data-operations",
    "href": "overview.html#data-operations",
    "title": "2  Overview",
    "section": "2.3 Data operations",
    "text": "2.3 Data operations\nThe data operations tab group contains a group of three possible operations to apply to your data set. All of these options are optional.\n\nThe screening tab allows you to remove units (e.g. countries) based on a data availability threshold. This can be useful to exclude any units with very low data availability. Screening can also be performed based on the proportion of zeroes. This is explained more in Chapter 5.\nThe imputation tab provides several simple approaches to estimating missing data points. Note that imputation should be used carefully and only for small amounts of missing data. If an indicator or unit has a high proportion of missing data points, it may be better to exclude it. This is explained in Chapter 6.\nThe outlier treatment tab uses a built-in algorithm to treat outliers. The reasons for doing this, and the methodology behind it, are explained in Chapter 7.\nEach operation is applied in order, so e.g. imputation will be applied the data set produced by the screening tab, if that was run. Outlier treatment will be applied to the imputed data set, if imputation was run. Although data operations are optional, it is not possible to change the order of data operations (e.g. you cannot do outlier treatment before imputation).\nIt is up to you which operations you apply. Usually it is a good idea to screen out any units with low data, and treat any major outliers. However these choices are subjective."
  },
  {
    "objectID": "overview.html#normalise",
    "href": "overview.html#normalise",
    "title": "2  Overview",
    "section": "2.4 Normalise",
    "text": "2.4 Normalise\nAfter the optional data operations, the normalisation tab gives several options for normalising indicators, i.e. bringing them onto a common scale ready for aggregation. This step is mandatory to calculate index scores, because aggregating indicators on very different scales hardly ever makes any sense. Normalisation is explained in Chapter 8."
  },
  {
    "objectID": "overview.html#compose-index",
    "href": "overview.html#compose-index",
    "title": "2  Overview",
    "section": "2.5 Compose Index",
    "text": "2.5 Compose Index\nThe Compose Index tab allows you to aggregate your normalised indicator data, in order to calculate all scores up to the index level. It aggregates using one of the selected methods, using the weights specified in your input data.\nThe immediate output here is a results table. The results are used in the rest of the app, and can be visualised and explored in the following tabs. Later, you also have the option to adjust the index, and you can anyway go back and alter the methodology in the previous tabs."
  },
  {
    "objectID": "overview.html#explore",
    "href": "overview.html#explore",
    "title": "2  Overview",
    "section": "2.6 Explore",
    "text": "2.6 Explore\nThe explore group of tabs gives various options for visualising and analysing the results (the index scores) as well as the indicator data itself.\n\nFirst, the map tab allows the index, or any indicator, to be displayed as choropleth map. This will only work if your data is at the country level, AND the indicator codes correspond to ISO alpha-3 codes, as mentioned previously.\nThe bar tab is similar to the map tab, but shows index or indicator scores ordered in a bar chart, and can be used for non-country data.\nThe bubble tab gives a sophisticated interface for plotting any indicator/index against any other, and allows points to be sized and coloured according to other variables and groups.\nThe descriptive stats tab allows the statistics of each indicator to be explored in detail via distribution plots, and also summarises potential issues with individual indicators.\nFinally, the correlations tab generates correlation heatmaps of any group of indicators against any other. This can be useful for seeing at a glance how indicators are related, and can also help to spot errors in directionality."
  },
  {
    "objectID": "overview.html#unit-profiles",
    "href": "overview.html#unit-profiles",
    "title": "2  Overview",
    "section": "2.7 Unit profiles",
    "text": "2.7 Unit profiles\nThe unit profiles tab allows you to zoom in on the scores of any selected unit. The aim is to go back to the raw data and show why each unit has a high or low score, in terms of its underlying indicators. Top and bottom-ranking indicators are listed, and unit reports can be dowloaded as HTML files."
  },
  {
    "objectID": "overview.html#adjust",
    "href": "overview.html#adjust",
    "title": "2  Overview",
    "section": "2.8 Adjust",
    "text": "2.8 Adjust\nThe last tab group is for adjusting the index and exploring its robustness.\nThe first tab, called reweighting, allows to explore the effects of changing the weights at any level, and compare the results with the weights currently used in the “compose” tab. You can save weight sets and then use them as the “official” set for the results by returning to the compose tab and using the saved weight set.\nThe removing elements tab explores the impact of removing indicators, or whole indicator groups, from the framework. It allows to see which indicators may perhaps have little effect on the results, therefore pointing to ways to reduce the indicator framework size if needed.\nFinally, the sensitivity analysis tab allows you to formally explore the impacts of assumptions made in the construction of the index, and estimate the uncertainty in the rankings. This is done by exploring alternative plausible ways to construct the index."
  },
  {
    "objectID": "overview.html#export-and-saving-session",
    "href": "overview.html#export-and-saving-session",
    "title": "2  Overview",
    "section": "2.9 Export and saving session",
    "text": "2.9 Export and saving session\nOptions for saving the session and exporting the data are found in the “Save/export” dropdown in the top-right of the navbar.\nAt any point in the app, you can save your session by clicking the “Bookmark” button. This uses Shiny’s bookmarking capability to save the state of the app, plus the uploaded data, to a bookmark directory. It then provides the user with a link to copy. To return to a previous session, you have to run run_gui() again (this establishes a Shiny session in your browser), then enter the link in the navigation bar. Of course, you have to be careful not to move or delete the \\shiny_bookmarks folder that is created when you bookmark the app, otherwise the link will not work.\nSimilarly, the results can be exported to Excel at any point (after successful data upload) by clicking the “Export to Excel” button. This writes the data, index structure and any results to a spreadhseet.\nFinally, if you wish to switch to R and use the COINr package, you can use the “Export to R” button to download the “coin” which has been created by the app, and subsequently use it with COINr in R."
  },
  {
    "objectID": "app_layout.html",
    "href": "app_layout.html",
    "title": "3  App layout",
    "section": "",
    "text": "The app aims for a user-friendly layout based on a main window, a side panel and a navbar at the top.\n\n\n\nApp layout\n\n\nThe navbar allows you to navigate between one tab and the next in the app. In general, you should start at the leftmost tab (“Data Input”, which allows you to input data), and work one tab at a time to the right. Specifically, the first tabs are for building the index, the results can be viewed in “Compose Index”, and the tabs to the right of this are for analysing the results and making adjustments.\nIn the top right of the navbar are the Save/Export options for saving to Excel and R, and saving the app session (see previous chapter for details), and the app documentation which can be accessed by clicking the question mark icon in the top right.\nIn each tab, the side panel contains the controls. These may be options to apply data operations, or settings to control the visualisations. The sidebar can be hidden by clicking the “&lt;” arrow.\nThe main window contains the outputs of that tab - these may be plots, tables, maps and text."
  },
  {
    "objectID": "data_input.html#template-and-example",
    "href": "data_input.html#template-and-example",
    "title": "4  Data input",
    "section": "4.1 Template and example",
    "text": "4.1 Template and example\nBefore explaining the specific requirements of the input spreadsheet, it is definitely worth downloading both the input template and the example input data, which are both available at the links in the “Data input” tab.\n\nWe recommend that you carefully read the instructions here, and compare to the example data set, which should give a good understanding of how to correctly format your input.\nThe example data set is composite indicator developed by FIND (the organisation that developed the composer app) which is designed to prioritise resources for medical diagnosis of cervical cancer. However in the context of this documentation, it simply serves as an example data set to show the functioning of the app and the setup of the input files."
  },
  {
    "objectID": "data_input.html#idata-table",
    "href": "data_input.html#idata-table",
    "title": "4  Data input",
    "section": "4.2 iData table",
    "text": "4.2 iData table\nThe first of the two tables to input into the app is called “iData”, which is short for “indicator data”. This table is unsurprisingly where you enter the data for your indicators, but also the codes and names of each indicator.\n\n\n\nExtract of iData example table\n\n\nThe figure above shows the first few rows and columns of the example data. Notice first of all that each row is a unit (countries here), and each column describes things about each unit, such as its code, name, and also its values for each indicator. Let’s now go through each column in turn - we divide into required and optional columns.\n\n4.2.1 Required columns\nThe uCode column should contain a short alphanumeric code for each unit. For example, if units are countries it is advisable to use ISO alpha-3 codes (as in the example data). Otherwise, some requirements for these codes:\n\nUnique (not the same as other iCodes or uCodes\nNo spaces\nMust start with a letter, but can contain numbers otherwise\nAvoid special characters, underscores are OK though\nIdeally should be short (e.g. &lt;10 characters) but descriptive\n\nThese requirements are necessary because uCodes are used by the app to reference each unit in calculations.\nThe uName column gives the full name of the unit (e.g. the country name). Here, there are no specific restrictions other than that you must specify a name for each unit, i.e. don’t leave any blanks.\nBoth the uCode and uName columns must be present - do not remove them or change their names.\n\n\n4.2.2 Optional columns\nThe uCode and uName columns are the only columns that must be present - all other columns are data columns or group columns which are named according to your data. The purpose of each column will be specified later in the iMeta table. Keep in mind that at least one indicator column needs to be present, and ideally several, to make a useful composite indicator.\nIn the example data, columns G onwards are indicator columns. The first row of each column is the indicator code, which is cross-referenced in the iMeta table (see next section). These codes must be unique and follow rules similar to the uCodes. There are no restrictions on the number of indicator columns, but the entries in each column must be numeric (no text), and any missing data should be left as a blank (don’t write “n/a”, for example).\nAgain following the example above, columns C, D and E are group columns, which specify unit groupings, such as continents and income groups in the country context. Grouping variables are not used as indicators, i.e. they are not used in the calculation of the index, but can be optionally used in plots, as well as missing data imputation. Notice that unlike indicator columns, the group columns can contain text. There are no specific limitations on the numbers of groups within each grouping variable, but consider that having a very large number of groups may not be very useful in sensibly dividing units. You can have as many grouping columns as you need, but also group columns are completely optional.\nIt is also possible to include additional columns that are are simply passed through, i.e. they are not used as indicators or as groups. These columns must be tagged as “Other” in the iMeta table (see next section).\nIn summary, the iData table should provide, for each unit, its code, name, and its values for each indicator and (optionally) grouping variable."
  },
  {
    "objectID": "data_input.html#imeta-table",
    "href": "data_input.html#imeta-table",
    "title": "4  Data input",
    "section": "4.3 iMeta table",
    "text": "4.3 iMeta table\nThe iMeta table provides the metadata for each indicator, and also specifies the structure of the index. It should contain a row for each column in iData (except the uCode and uName columns) AND also rows for each aggregate level. It is a little more complex than the iData table.\n\n\n\niMeta example table\n\n\nAll the columns shown in the example iMeta table are required.\nBeginning with the iCode column, this is required to contain all the column names in the iData table (inclduing groups, etc.), as well as any aggregates that are created by aggregating indicators. The point of the iMeta table is to give further details about each variable. Therefore the codes here need to be exactly the same as the iData column names (excluding uName and uCode) - remember that codes are case-sensitive!\nNotice that the first rows of the table also have “1” in the Level column and “Indicator” in the Type column. This tells the app that they are indicators, and at level 1 (the indicator level). From row 17 downwards there are some rows with level = 2: these are “aggregates”, i.e. they are variables (actually composite indicators themselves) that are created by aggregating indicators together. At level 2, therefore, there should be one iCode for each group of indicators to be aggregated. Finally, at Level 3, in this case is the index: there is only one iCode at this level, and it is created by aggregating everything in Level 2 together.\nThe Parent column defines which indicators fall into which groups: specifically it specifies which group each indicator aggregate belongs to in the level immediately above it. For example, the parent of the mortality rate indicator is “epidemiological_impact” (an aggregate at level 2). The parent of “epidemiological_impact” is “cxca_prioritization_index” (level 3), and the parent of “cxca_prioritization_index” is left blank because it is the top level. This allows a framework to be defined of any number of levels.\nKeep in mind that every indicator or aggregate must have a parent, unless it is at the top level. You cannot define a parent that is more than one level above - if needed, define intermediate aggregates with only one indicator/aggregate.\nThe other columns are more straightforward. The iName column is analogous to the uName column in iData, and gives the full name of the indicator. The Direction column specifies the conceptual direction of the indicator: if higher values of the indicator should imply higher index scores, the direction should be “1”. Otherwise if higher indicator values should imply lower index scores, the direction should be “-1”. In an index measuring environmental sustainability, for example, % renewable energy would have direction 1, and CO2 emissions per capita would have direcion -1.\nThe Weight column gives the initial weight assigned to each indicator and aggregate. Weights are used when aggregating groups of indicators and aggregates to calculate aggregate scores. Importantly, weights are relative within aggregation groups - they will be rescaled by the app to sum to 1. This means that for three indicators in one aggregation group, setting the weights as (1, 1, 1) is the same as setting them to (2, 2, 2) - in either case, the indicators will each be weighted as 1/3.\nWe now return to the Type column. Here, each row must either be assigned a type of “Indicator” (anything at level 1), “Aggregate” (any aggregates created from aggregating indicators - level 2 upwards), or else “Group” or “Other”. The last two types are used to label columns in iData that are not part of the index. Type = “Group” is used to point to grouping variables, as described in the previous section. Type = “Other” is for any variables to simply pass through and ignore. Notice that for these last two types the Direction, Weight, Parent and Level columns should be left blank.\nIt is important to carefully cross-check between the iData and iMeta tables, making sure that all columns in iData are defined in iMeta (except uCode and uName), and the formatting rules are carefully followed."
  },
  {
    "objectID": "data_input.html#upload",
    "href": "data_input.html#upload",
    "title": "4  Data input",
    "section": "4.4 Upload",
    "text": "4.4 Upload\nWith your input data correctly prepared, you can now upload it to the app. On the “Overview tab”, select the “Upload data” tab in the sidebar and browse to the location of your input data on your computer by clicking the “Browse” button. Having selected the file, click the “Load data” button.\nAt this point, either the data upload will be successful or not. Here’s what to do.\n\n4.4.1 Successful\nIf the data upload is successful, the app should output some information about your data to relay what it has understood. In the main window you should see a box with some text output summarising your input. This displays the number of units, indicators, groups, and details about the index structure. Check that this output is what you expect.\n\nNext to the text summary is a sunburst plot of the framework you have specified, which should look something like this:\n\nThis is a plot of the index framework as specified in your iMeta table. Hovering over segments will show indicator names, and clicking on segments will zoom in on lower levels. Double click to reset the plot. Like most plots in the app, a snapshot of the plot can be downloaded as a png file by clicking the small camera icon in the upper right of the plot.\nThe framework plot also shows the effective weight of each indicator and aggregate in the framework, as a result of the weights specified in iMeta and the index structure. Notice that in our example there are two equally-weighted dimensions: “Country readiness”, and “Epidemiological Impact”, but these have different numbers of indicators within them. As a result, each indicator in “Country readiness” is weighted less individually than each in “Epidemiological Impact”. This is important to consider in defining the index structure.\nOn uploading the data there will also be a pop-up notification which reports whether your data has been recognised as country data or not. Data is recognised as country data if the uCodes correspond to ISO alpha-3 codes, as mentioned previously. This enables the maps later in the app. If you have made any mistakes with your ISO codes the app will try to point to them, or if no ISO codes are present it will assume you are not analysing country data and disable the mapping feature.\nFrom here, if you are happy with the details reported by the app, you can move to the next tab.\n\n\n4.4.2 Unsuccessful\nIt is not unlikely that you will have made a mistake the first time that you try to upload your data. Don’t worry! The input is a little complex and it is easy to make errors. The app will try to return helpful error messages, which should point to common problems and give the corresponding solutions.\nHere are some common problems:\n\nMismatch between iMeta and iData tables: remember that codes are case-sensitive, and cross check very carefully to ensure that all columns names from iData are in iMeta (excluding uCode and uName), and all iCodes except those with Type = “Aggregate” are columns in iData.\nNon-numeric data: make sure each column of data is actually formatted as numeric. Even it looks like a number, Excel may have interpreted it as text. In Excel, by default, a cell formatted as a number will be right-aligned, whereas text is left-aligned (see below).\n\n\n\nAggregates with no “children”: avoid specifying an aggregate in iMeta which is not the parent of at least one indicator or aggregate.\nAltering spreadsheet: try above all to avoid modifying the spreadsheet in unexpected ways. For example, do not add extra or numbers in cells near the tables. Do not change the names of required columns, and don’t move tables, or rename tabs. You CAN add extra tabs to the spreadsheet with other calculations as the app will only look for the iData and iMeta tabs."
  },
  {
    "objectID": "data_input.html#whats-next",
    "href": "data_input.html#whats-next",
    "title": "4  Data input",
    "section": "4.5 What’s next",
    "text": "4.5 What’s next\nFrom here, things get a lot smoother: the app should now work with fairly minimal interventions on your part. Move to the “Data operation” tab group to begin processing your data!"
  },
  {
    "objectID": "screening.html#about",
    "href": "screening.html#about",
    "title": "5  Unit screening",
    "section": "5.1 About",
    "text": "5.1 About\nIndicator data typically comes from different sources, and very often has missing values. It is also common that some units have more missing data (over the full indicator set) than others. This is often seen in country-level data where developing countries have less capacity for data collection, and can have very low data availability rates.\nAlthough in principle a composite score can be calculated for a unit even with large amounts of missing data, it will only be calculated using the indicators for which data is available. This can result in a skewed and misleading score which will be missing many parts of the concept to be measured. A simple remedy here is to simply exclude any countries from the index calculation: for example, a possible rule of thumb could be to exclude any unit with less than 66% data availability.\nConsider that even if a unit is excluded, it doesn’t imply discounting it completely. It can still be included (more qualitatively) in an analysis, presenting the indicators for which data is available.\nFor dealing with small amounts of missing data, you can also consider imputation, which is explained in Chapter 6."
  },
  {
    "objectID": "screening.html#how",
    "href": "screening.html#how",
    "title": "5  Unit screening",
    "section": "5.2 How",
    "text": "5.2 How\nThe {composer} app has a simple tool for screening units. In the sidebar, the “Screen units by” drop-down allows you to select whether to screen units on the basis of missing data, non-zero values, or both.\n\nThe box below lets you set the minimum proportion, which is used as the threshold value, below which units are excluded. Clicking “Run” will apply this operation to the data you uploaded and generate a new modified data set with units excluded that are below the threshold.\n\nTo see give an example - if there are ten indicators in the data set and the threshold is set at 0.66 data availability:\n\nIf unit A has five missing data points it will be excluded\nIf unit B has two missing data points, it will be included\n\nThe option to apply to non-zero values is similar but considers zeros instead of missing data. For example, a unit that has five zeroes as its indicator values will be excluded if we set the threshold at 0.66. You can also set the app to screen based on both criteria (missing data OR zeroes).\nWhen the operation is run, a table will appear showing the modified data set. Any units that have been excluded will be highlighted in red. Summary statistics are also given showing the total number of included and excluded units.\n\nNotice that the table, like other tables in the app, can be copied or downloaded using the buttons. Most tables are also searchable with the search box, and sortable by clicking on the column headings.\nThe result of the screening operation is that from this point on, the removed units will no longer be present in the analysis. However, you can change the screening parameters and click “Run” again to change the units that are screened out. Additionally, you can click “Remove operation” to remove the operation completely from the data workflow."
  },
  {
    "objectID": "imputation.html#about",
    "href": "imputation.html#about",
    "title": "6  Imputation",
    "section": "6.1 About",
    "text": "6.1 About\nImputation involves estimating missing data, and the accuracy of the estimate is dependent on many factors, such as the number of missing data points and distributions of indicators. The {composer} methods for imputation are simple, but this also makes them easy to understand. When imputing data it is always important to review the imputed data points to see whether the results are sensible.\nAll methods implemented in the app are univariate, i.e. each indicator is treated separately. The first two approaches are simply to substitute missing data points with the indicator mean or median. This means that for a given indicator, we calculate the mean or median of all observed data points, then any missing values will recieve this value.\n\n\n\nMean substitution\n\n\nA slightly more sophisticated approach is to use the group mean or median. If you have specified grouping variables in your input data (see Chapter 4), you can restrict the mean or median estimates to the unit groups. For example, we may want to impute an indicator by using the mean within country income groups. This may be more accurate if your indicator values are likely to be more similar within groups.\n\n\n\nGroup median substitution using income group\n\n\nAs with all data operations it is important to think carefully about which approach is most suited to your data. Consider that imputation is completely optional - the index can still be calculated without imputation. Moreover, you can choose to remove units with low data availability in the “Unit Screening” tab - see Chapter 5. You can also set a data availability limit for each aggregation - this is explained more in Chapter 9."
  },
  {
    "objectID": "imputation.html#how",
    "href": "imputation.html#how",
    "title": "6  Imputation",
    "section": "6.2 How",
    "text": "6.2 How\nIn the app, the methods discussed above can be easily run. In the sidebar, the “Impute using” dropdown allows you to select from one of the four methods - mean, median, group-mean and group-median.\n\nIf a group method is selected, AND you have included grouping variables in your input data, these should be available to select in the “Use group” dropdown - selecting a grouping variable will use this as the basis for grouped imputation.\nWhen you click “Run”, the selected imputation method will be applied. This will generate a new imputed data set which will be displayed in a table. The number of missing data points before and after imputation will be reported, and the specific points that have been imputed will be highlighted green in the table. At the bottom of each column, the number of missing data points is reported. It is important to check that the imputed values are sensible, as imputation can sometimes have unexpected results.\n\nIn most cases, all missing data points will be imputed. The exception is when you impute by a unit group, and there are missing values in your grouping variable. For data points with missing group values, the app will return the data points as still missing.\nAs with other data operations, you can re-run the operation and change specifications, and this will overwrite the previous imputed data. You can remove imputation from the the data pipeline completely by clicking “Remove operation”."
  },
  {
    "objectID": "outliers.html#about",
    "href": "outliers.html#about",
    "title": "7  Outlier treatment",
    "section": "7.1 About",
    "text": "7.1 About\nBefore explaining how to treat outliers, let’s explain the “why”. Outliers are roughly defined as data points that don’t fit the rest of the distribution. Consider the artificial example below.\n\n\n\n\n\nExample of a distribution with an outlier.\n\n\n\n\nHere, clearly the data point with a value of 10, does not fit the rest of the distribution.\nOutliers can exist because of errors in measurement and data processing, and should always be double-checked. But often, they are simply a reflection of reality. Outliers and skewed distributions are common in socio-economic variables.\nThe reason why we may want to treat outliers is that in composite indicators, before aggregating we typically normalise the data by scaling it onto a common range (e.g. 0-100). In the above example, this would mean that most units would get a low score, because the scale has been defined by the outlier.\nThis may or may not be the result you wish to obtain. If, for that indicator, you wish to acknowledge that the outlying point is exceptional, then it is better not to treat the data. If however, you would like the scale to be more defined by the large majority of points, you may wish to treat the outlier. This would mean that the outlier still has the highest score, but not by so much.\nAgain, this does involve changing data points, but it is only done in order to more effectively aggregate indicators together.\nThe {composer} app has an automatic outlier treatment algorithm which treats outliers at a single click. The methodology follows that used by the European Commission, among others, and is as follows.\nFor each indicator separately:\n\nCheck skew and kurtosis value\nIf absolute skew is greater than 2 AND kurtosis is greater than 3.5:\n\nSuccessively Winsorise up to a maximum of five points. If either skew or kurtosis goes below thresholds, stop. If after reaching the maximum number of points, both thresholds are still exceeded, then:\nReturn the indicator to its original state, and perform a modified log transformation.\n\nIf the indicator does not exceed both thresholds, leave it untreated.\n\nHere, the skew and kurtosis thresholds are used as simple indicators of distributions with outliers.\nWinsorisation involves reassigning outlying points to the next highest or lowest point, depending on the direction of the outlier. In the example above, this would involve taking the outlier with a value of 10, and reassigning it to the maximum value of the observed points except that one. This would result in the following:\n\n\n\n\n\nWinsorised distribution.\n\n\n\n\nThis treatment can be applied iteratively, in case of multiple outliers.\nThe log transformation involves applying a scaled log-transformation that reshapes the entire distribution. It is most suitable for naturally skewed distributions such as log-normal distributions.\n\\[\nx' = \\log(x-\\min(x) + a)\\\\\n\\text{where:} \\;\\;\\;  a = 0.01(\\max(x)-\\min(x))`\n\\]\nThis transformation is effectively a log transformation with a small shift, which ensures that negative values can also be transformed. It looks like this:\n\n\n\n\n\nThis shows that the initially skewed distribution with outliers has been transformed to a distribution that is reasonably normal-looking. It has also had the effect of changing the scale of the distribution, but this doesn’t matter because all indicators will anyway be normalised onto a common scale - see Chapter 8."
  },
  {
    "objectID": "outliers.html#how",
    "href": "outliers.html#how",
    "title": "7  Outlier treatment",
    "section": "7.2 How",
    "text": "7.2 How\nThe outlier treatment algorithm is automatically implemented in the {composer} app. There are no parameters to adjust here, it is simply a choice of running the data treatment procedure, or not. To run data treatment, click the “Run” button.\n\nOn running the treatment, the app will return a summary of which indicators had outliers before treatment (using the skew and kurtosis thresholds mentioned above), and any that still have outliers after treatment (since outlier treatment does not always successfully deal with all outliers).\nA table of data is also generated which highlights points that have been Winsorised or log-transformed, and summarises the data treatment applied to each indicator.\n\nClicking on a column in the table will generate a scatter plot in the sidebar, showing the indicator before and after treatment, and illustrating how the data points have been changed. In the example below, four points have been Winsorised."
  },
  {
    "objectID": "normalisation.html#about",
    "href": "normalisation.html#about",
    "title": "8  Normalise",
    "section": "8.1 About",
    "text": "8.1 About\n\n8.1.1 Linear methods\nThere are several normalisation methods available in the {composer} app. The default is called “min-max”, and it simply rescales an indicator onto a specified interval with a minimum value \\(l\\), a maximum value \\(u\\), and consequently a range \\(u-l\\). By default in the app, indicators are scaled between 0 and 100.\n\\[ x' = \\frac{ x - x_{\\text{min}} }{ x_{\\text{max}} - x_{\\text{min}} } \\times (u-l) + l\\]\nwhere \\(x'\\) is the normalised indicator value. For example, if \\(l=0\\) and \\(u=100\\) this will rescale the indicator to lie exactly onto the interval \\([0, 100]\\). An example of the min-max transform, for both negative and positive directionality indicators, is as follows.\n\n\n\n\n\nThe min-max approach is recommended as the default because it is easy to understand and is suitable in many cases.\nA similar transformation is to take z-scores, which instead use the mean and standard deviation as reference points:\n\\[ x' = \\frac{ x - \\mu_x }{ \\sigma_x } \\times a + b\\]\nwhere \\(\\mu_x\\) and \\(\\sigma_x\\) are the mean and standard deviation of \\(x\\). The indicator is first re-scaled to have mean zero and standard deviation of one. Then it is scaled by a factor \\(a\\) and moved by a distance \\(b\\). This is very similar to the min-max transformation in that it can be reduced to multiplying by a factor and adding a constant, which is the definition of a linear transformation. However, the two approaches have different implications. One is that Z-scores will generally be less sensitive to outliers, because the standard deviation is less dependent on an outlying value than the minimum or maximum.\nThe z-score transformation looks like this, if scaled to have mean 0 and standard deviation 1:\n\n\n\n\n\n\n\n8.1.2 Rank-based approaches\nThe other two normalisation approaches are different in that they are based on ranks, and are therefore nonlinear transformations. The first is called “Borda scores”, and this simply assigns a score to each indicator value based on its rank, with a 0 given to the lowest value, and \\(n-1\\) to the highest value (where \\(n\\) is the number of observations). An example applied to some random data looks like this:\n\n\n\n\n\nClearly this is not linear. However, rank based approaches have a nice property, that they automatically deal with outliers.\nThe final normalisation method is called “percentile ranks”. Percentile ranks are defined as the “percentage of scores in its frequency distribution that are less than that score” (from Wikipedia). This is similar to a rank-based approach but has one important difference - it is not dependent on the number of observations.\nThis can be important when some indicator have low data availability. For a data set with 50 units, say that one indicator x1 has 50 observations, and x2 has 30 (the others are missing data). Applying Borda scores to x1 will result in a normalised indicator with scores between 0 and 49, whereas applying the same to x2 will result in scores between 0 and 29. This causes a problem because they are on different scales.\nPercentile ranks avoid this because they scale each indicator onto the \\([0,1]\\) interval (strictly, this is quantile ranks). An example is as follows.\n\n\n\n\n\n\n\n8.1.3 Which to use?\nGenerally, the default approach is to use min-max, since it is easy to understand and works fairly well. However, min-max is sensitive to outliers, so be careful to check and visualise the normalised scores to ensure the results fit your needs.\nZ-scores are harder to interpret, but are less sensitive to outliers. In reality, z-scores are not often used but could be useful in some contexts.\nRank based approaches can be attractive for automatically dealing with outliers. They make every indicator into a uniform distribution. This can be a simple and fair way to normalise indicators. In this case, the percentile rank approach is probably preferable since it is not affected by missing data points."
  },
  {
    "objectID": "normalisation.html#how",
    "href": "normalisation.html#how",
    "title": "8  Normalise",
    "section": "8.2 How",
    "text": "8.2 How\nNormalisation in the app is straightforward. Siimply select the normalisation method you want to use from the drop-down menu.\n\nIf you select min-max or z-score, you will additionally have the option to set the parameters (upper/lower bounds, and mean/standard deviation, respectively). The other two methods have no parameters to set.\nClicking “Run” will apply the normalisation method to the data, and generates a table with the normalised data set. As in other tabs, clicking on a column in the table will show a scatter plot of the indicator in the sidebar, before and after normalisation.\n\nYou can change and adjust the normalisation simply by altering the specifications and clicking “Run” again, which will overwrite any existing normalised data."
  },
  {
    "objectID": "compose.html#about",
    "href": "compose.html#about",
    "title": "9  Compose",
    "section": "9.1 About",
    "text": "9.1 About\nCalculating index scores is done by mathematical aggregation of indicators. As discussed in Chapter 8, indicators must be normalised first so that they are on a common scale.\nThere are two simple aggregation methods available in the app. The first is the weighted arithmetic mean. Denoting a group of indicators as \\(x_i \\in \\{x_1, x_2, ... , x_d \\}\\), the weighted arithmetic mean is calculated as:\n\\[ y = \\frac{1}{\\sum_{i=1}^d w_i} \\sum_{i=1}^d x_iw_i \\]\nwhere the \\(w_i\\) are the weights corresponding to each \\(x_i\\). Here, if the weights are chosen to sum to 1, it will simplify to the weighted sum of the indicators. In any case, the weighted mean is scaled by the sum of the weights, so weights operate relative to each other.\nClearly, if the index has more than two levels, then there will be multiple aggregations. For example, there may be three groups of indicators which give three separate aggregate scores. These aggregate scores would then be fed back into the weighted arithmetic mean above to calculate the overall index.\nThe arithmetic mean has “perfect compensability”, which means that a high score in one indicator will perfectly compensate a low score in another. In a simple example with two indicators scaled between 0 and 10 and equal weighting, a unit with scores (0, 10) would be given the same score as a unit with scores (5, 5) – both have a score of 5.\nAn alternative is the weighted geometric mean, which uses the product of the indicators rather than the sum.\n\\[ y = \\left( \\prod_{i=1}^d x_i^{w_i} \\right)^{1 / \\sum_{i=1}^d w_i} \\]\nThis is simply the product of each indicator to the power of its weight, all raised the the power of the inverse of the sum of the weights.\nThe geometric mean is less compensatory than the arithmetic mean – low values in one indicator only partially substitute high values in others. For this reason, the geometric mean may sometimes be preferred when indicators represent “essentials”. An example might be quality of life: a longer life expectancy perhaps should not compensate severe restrictions on personal freedoms.\nRegardless of the aggregation method, the aggregation follows the structure of the index from the lowest level upwards. The indicators (at level 1) are first aggregated within their groups to give the aggregate scores at level 2. The aggregates at level 2 are then aggregated together within their groups to give the aggregates at level 3, and so on, up to the index level.\nAt the aggregation step it is also possible to build in data availability restrictions, which is available in the {composer} app. By default, for a given unit, an aggregate can be given a score as long as at least one data point is available - the aggregation methods above take the mean only over the available points. For example, consider the indicator values of two units and their aggregate scores:\n\nUnit A has normalised indicator values Ind1 = 20, Ind2 = 35, Ind3 = 70, Ind4 = 18 and Ind5 = 12 for a given indicator group. The aggregate score is calculated as the equally weighted mean: 31.\nUnit B has missing data for four out of the same five indicators, but has a value for Ind4, which is 65. The aggregate score is calculated as the mean of the available points, which gives 65.\n\nHere, the second case can be quite misleading since the score is based on an indicator group with 80% missing data.\nTo avoid this, you can set a data availability limit which is applied individually to each aggregation. For example, setting the limit at 0.6 would mean that, for each unit and each aggregation, a score is only calculated if the unit has at least 60% data availability (in that aggregation group) - if the availability is lower, the score is treated as a missing value.\nThis safeguard is usually a sensible approach to avoid overstating what is actually known. Note that this is different from the overall unit screening described in Chapter 5, because it is applied to each aggregation group individually."
  },
  {
    "objectID": "compose.html#how",
    "href": "compose.html#how",
    "title": "9  Compose",
    "section": "9.2 How",
    "text": "9.2 How\nIn the app, the aggregation methods mentioned above can be selected in the sidebar under the “aggregation type” dropdown.\n\nUnderneath this, there is the option to select the weight set to use in the aggregation. Weight sets are named sets of weights for all indicators and aggregates. The default, “Original”, is the set of weights specified in the “iMeta” table in your input data. Alternatively, the “Equal” weight set specifies equal weights everywhere.\nLater, in Chapter 15, you will discover how to build alternative weight sets in the “Reweighting” tab of the app, which can be selected here. If you have not been to the Reweighting tab yet and built any weight sets, the only two options will be those mentioned above. See Chapter 15 for more details on weight sets.\n\nThe final input is the data availability threshold which was discussed in the previous section. If you don’t want to impose any data availability threshold, simply set this to zero. Consider also that if you have imputed your data, you will probably have no missing data points, so the data availability threshold will have no effect.\nFinally, click the “Run” button to generate the results. This will generate a summary table of the results, colour-formatted to help highlight high and low values. The table rows are sorted by the highest index score downwards, and the columns are sorted from the highest level downwards. You can sort the table by different columns by clicking on the column headers, and search for particular units using the search box.\n\nKeep in mind that it is up to you to interpret the results correctly: in some indexes, higher values may be “better”, in others they may be “worse”. This may be a good moment to look critically at the results and consider whether the index measures what it is you want to measure, and whether the directionality of each indicator, each dimension and the index itself is suitable. Moreover, you may wish to pass prelimary results to topical experts and stakeholders as a “reality check” - this may result in some feedback at this initial stage."
  },
  {
    "objectID": "map_bar.html#maps",
    "href": "map_bar.html#maps",
    "title": "10  Maps and bar charts",
    "section": "10.1 Maps",
    "text": "10.1 Maps\nMaps can be generated in the “Map” sub-tab in the “Explore” dropdown menu in the navbar. As mentioned elsewhere, maps can only be plotted if your input data is at the country level and uses ISO alpha-3 codes as its “iCodes” (see again Chapter 4). Otherwise, the map will be disabled.\nTo plot a map, simply select the indicator or aggregate of interest from the dropdown, and click “Run”. The dropdown menu here is sorted by the highest level downwards.\n\nThis will generate a choropleth map which is a world map where the colour of each country represents its score or value in the indicator.\n\nThe map is interactive, so hovering over a country will give details about its score. Hovering over the legend will highlight the countries in that score group, and clicking on legend entries will exclude or include countries within that range. The map can be zoomed and panned by using the mouse scroll wheel and by clicking and dragging, respectively. The map image may also be downloaded as an image using the download icon in the top right of the map window. You can also expand the plot window by clicking the expand button in the bottom right.\n\n\n\n\n\n\nCaution\n\n\n\nCountry borders are disputed in some areas can be politically sensitive. Always be aware of the environment that maps are presented in!"
  },
  {
    "objectID": "map_bar.html#bar-chart",
    "href": "map_bar.html#bar-chart",
    "title": "10  Maps and bar charts",
    "section": "10.2 Bar chart",
    "text": "10.2 Bar chart\nThe bar chart displays the same kind of information, but wsithout the spatial component. On the “Bar” sub-tab, select the indicator or aggregate to plot, then click “Run”.\n\nThe resulting bar chart in the main window will be sorted from the highest score downwards. The bar chart is also interactive and can be zoomed and panned.\n\nNote that if an indicator is selected to plot (i.e. from level 1), the bar chart will display the raw data, as it was input into the app. If an aggregate is selected, i.e. from level 2 upwards, then it will be displayed as a score. In this case, it is also possible to display the component scores for each country, as “chunks” of each bar, by clicking the “Show component scores” switch.\n\nIn the example here, this gives an idea of what is contributing to each score. Clicking on the legend entries will also add or remove each group from the plot.\nThe remaining switches allow the bar chart to be flipped to vertical (this can be be useful depending on the number of units and the length of names), and to toggle between unit names and unit codes. You can also select to plot a subset of the units, for example top 50, which can be useful when the number of units is quite large."
  },
  {
    "objectID": "bubble.html",
    "href": "bubble.html",
    "title": "11  Bubble chart",
    "section": "",
    "text": "The bubble chart, which is found in the “Bubble” sub-tab of the “Explore” tab group, is a powerful tool to compare the relationships between indicators and aggregates. Effectively it is a scatter plot between two variables, but can also map a third variable to the size of each point, and a grouping variable to the point colours. Note that colour mapping will only be enabled if you have entered a grouping variable with your input data.\nThe sidebar gives various controls. The first six dropdown menus control which indicators or aggregates to display on the plot: the x and y variables, plus size and colour.\n\nNotice that for the x and y variables you can also select the data set: here, selecting “Raw values” will show the indicator values before any treatment, normalisation and so on. These are, in other words, the “real” measured values. The “Normalised scores” are instead the indicator values after any data operations, AND normalised. For aggregate variables (e.g. the index, dimension scores etc.), you must select “Normalised scores” since these variables only exist as scores and not as raw (measured) values.\nAfter selecting the variables of interest, click the “Run” button. The plot will show the selected variables, and will also include two “threshold” lines which can be moved using the settings in the side panel. These are intended to be used to illustrate units that have passed certain significant thresholds (the meaning will be dependent on the selected indicators).\n\nThe bubble plot is interactive: hovering over points will momentarily filter to points of the same group. Clicking on the legend entries also allows to filter in/out each group. You can also zoom in and out and download the image using the controls in the top right.\nFurther controls on the bubble plot include:\n\nSwitches to enable log axes for the x and y axes\nA switch to enable and disable the threshold lines and set their values\nA “Highlight units” box, which can be used to select a subset of units to highlight on the plot"
  },
  {
    "objectID": "stats.html#table",
    "href": "stats.html#table",
    "title": "12  Indicator statistics",
    "section": "12.1 Table",
    "text": "12.1 Table\nThe table in the main window has one row for each indicator. The columns give some statistics of interest, focusing on statistics that might identify potential problems. The table from the example data set is shown here:\n\nThe min and max columns give the minimum and maximum, respectively. This is worth checking because it could identify erroneous points, or mistaken definitions. For example, if an indicator is a percentage, it should be generally between 0-100%.\nThe Availability column gives the data availability of that indicator. If the data availability is below 66%, the cell will be highlighted. In general, indicators with very low data availability are candidates for removal unless they are essential to the framework.\nThe Same column gives the percentage of values in the indicator which share the same value. If an indicator has a high percentage, this means that is relatively weak in differentiating between units, which is at the end of the day the role of indicators. Here, any indicator with more than 50% points having the same value is highlighted.\nThe skew/kurtosis column reports the skew and kurtosis. Since these measures are used to detect outliers (see again Chapter 7 for why we may want to check outliers), any indicators which pass the thresholds are highlighted. The thresholds are absolute skew &gt; 2, and kurtosis &gt; 3.5. An indicator has to exceed both thresholds to be flagged.\nThe final two columns, Collinear with and Neg. corr with give details of any indicators with which the indicators is collinear with (defined as correlation &gt; 0.9), or negatively correlated with (defined as correlation &lt; -0.4), within the same aggregation group at level 2. Collinearity between indicators can point to double counting, where effectively the same information is present in two indicators. Negative correlations can cause problems in aggregation, because high values of one indicator can cancel out low values of the other.\nAltogether, the table aims to highlight at a glance any possible statistical issues with indicators. Keep in mind that indicators are never “perfect”, and there will likely be various issues flagged in your data set. Of the criteria in the table, the data availability is probably the most important - indicators with low availability can add little, and in the worst case be misleading. The others can be considered as “small flags”, but if an indicator has multiple flags, it could be examined more closely to see whether it is really worth including it or not."
  },
  {
    "objectID": "stats.html#charts",
    "href": "stats.html#charts",
    "title": "12  Indicator statistics",
    "section": "12.2 Charts",
    "text": "12.2 Charts\nThe charts below the table allow you to visualise indicators and pairs of indicators.\n\nClicking on a row in the table will visualise the selected indicator in the left plot as either a violin plot, or as a histogram. The plot type can be changed by clicking on the “gear” icon in the top left of the plot.\nOn the right side, the scatter plot shows the same selected indicator on the x-axis. The indicator to plot on the y-axis is selected by clicking on the “gear” icon - there you can also change the axes to log axes if needed: this is useful to more clearly visualise skewed indicators."
  },
  {
    "objectID": "correlations.html#app-usage",
    "href": "correlations.html#app-usage",
    "title": "13  Correlations",
    "section": "13.1 App usage",
    "text": "13.1 App usage\nTo generate correlation plots use the sidebar options. By default, when clicking the “Run” button, all indicators should be correlated against all other indicators, resulting in a plot something like this:\n\nHere, we have additionally enabled the “Show values” switch, which shows the correlation values in each square, and the “Show groupings” switch (both found near the bottom of the side panel), which restricts to show only correlations between indicators within the same aggregation group.\nThe heatmap describes the correlation of the indicator labelled in the row, with the indicator labelled in the column, and the strength of the correlation is displayed as the colour - the colour scale is on the right. As mentioned above, what is usually of interest is very high or negative correlations, particularly between indicators within the same aggregation group.\nWe can select which groups to correlate against each other using the dropdown menus shown in the following figure:\n\nHere, the “Correlate” and “Against” dropdowns allow you to select the groups to correlate, and the “At level” dropdowns select the corresponding levels. Here, level 1 means all indicators within the selected group, but by changing to level 2, this would instead select all aggregates in level 2 within the selected group (presuming the selected group is at level 3 or higher). If this is not clear, it should be clearer after experimenting with selecting different groups and levels and seeing the results!\nA useful option for quickly spotting high and negative correlations is to enable the “Discrete colours” switch. When enabled, the heat map will use a discrete (categorical) colour scale such that:\n\n“High” correlations (correlation above 0.9) are coloured dark green\n“OK” correlations (correlation between 0.3 - 0.9) are coloured light green\n“Weak” correlations (correlation between -0.4 - 0.3) are coloured grey\n“Negative” correlations (correlation less than -0.4) are coloured red\n\nAlthough this clarifies things, please consider that these thresholds are rules of thumb and are somewhat subjective.\n\nThe figure above highlights two indicators that are effectively collinear (incidence rate and mortality rate) and could be reexamined."
  },
  {
    "objectID": "profiles.html",
    "href": "profiles.html",
    "title": "14  Unit profiles",
    "section": "",
    "text": "The unit profiles tab generates a summary report for any selected unit (often countries). To see a unit profile, use the “Select units” dropdown in the sidebar to select the unit of interest, and click “Run”.\n\nAt the top of the generated unit profile, the index score and rank are reported in value boxes. This is followed by a bar chart plotting the index scores, and highlighting the position of the selected unit. Using the side panel controls, you can control whether the bar chart shows the underlying component scores of the index, and whether to show the unit codes or names.\nThe table on the right side gives a summary of the scores and ranks of the selected unit at the index level and the underlying aggregate levels.\n\nFinally, the “Top ranking” and “Bottom ranking” tables report the five highest-ranking and lowest-ranking indicators of the selected unit. These can be viewed as the (relative) “strengths” and “weaknesses” of the unit respectively.\nIn the sidebar there is a button which allows the report to be downloaded as an HTML document. This is a standalone but interactive HTML file which can be shared and viewed in any browser."
  },
  {
    "objectID": "reweighting.html",
    "href": "reweighting.html",
    "title": "15  Reweighting",
    "section": "",
    "text": "Weights are used at all levels of the composite indicator to aggregate indicators and aggregates up to the levels above. For example, denoting a group of indicators as \\(x_i \\in \\{x_1, x_2, ... , x_d \\}\\), the weighted arithmetic mean is calculated as:\n\\[ y = \\frac{1}{\\sum_{i=1}^d w_i} \\sum_{i=1}^d x_iw_i \\]\nwhere the \\(w_i\\) are the weights. Similarly, the weighted geometric mean has its weights as exponents:\n\\[ y = \\left( \\prod_{i=1}^d x_i^{w_i} \\right)^{1 / \\sum_{i=1}^d w_i} \\]\nThe Reweighting tab allows you to adjust the weights at any level of the composite indicator, compare with the current results, and to save as new weight sets. This tab can be viewed as a sandbox where you can try new weighting combinations and view the preliminary results. To actually use the new weights you save them as a weight set and then select them in the “Compose” tab. This will now be explained in more detail.\nBegin by selecting the level at which you wish to adjust the weights using the “Select framework level to adjust weights” input, in the sidebar. Here, as usual, level 1 is the indicator level and so on up to the index level. By default, the level will be selected as one level down from the index.\n\nWhen the level is selected, below you will see slider inputs for the indicators/aggregates in that level. In this example, we are seeing the weights for the three aggregates below the index (indicator codes are used as labels). These sliders can be used to adjust the weights to the desired values. Remember that weights are relative and will be rescaled to sum to 1 within each aggregation group.\nAfter making any adjustments to the weights, to see the results with the selected weights, click the “Recalculate” button below the weight sliders: this will calculate the new results at the index level and display in a comparison table:\n\nThis table will show the ranks of the units using the new weights, compared to the ranks using the weight-set selected in the “Compose” tab, along with the rank differences and absolute rank differences, which can be sorted using the table headers. It may be of interest, for example, to look for the units with the greatest absolute rank change as a result of the new weights.\nImportantly, the reweighted results generated in this tab are generated in parallel to the main results (which come from the “Compose” tab) for the purposes of experimentation, and exist only within the Reweighting tab. To actually apply these new weights to your composite indicator you must do the following:\n\nGo to the “Save weights” box in the side panel (at the bottom), enter a name for your new set of weights, and click “Save”. NOTE: this will only work if you have clicked “Recalculate” first.\nGo back to the “Compose” tab, select the new weight set in the “Weight set” drop-down, and click “Run”.\n\nHaving done this, your new weight set is now “active” in the rest of the app and the new results will be reflected in all the visualisation tabs and so on.\nThere is no limit on the number of weight sets that you can create, but it is important to realise that the composite indicator results are generated from the Compose tab, whereas the Reweighting tab is a sandbox for creating new weight sets."
  },
  {
    "objectID": "remove_elements.html",
    "href": "remove_elements.html",
    "title": "16  Remove elements",
    "section": "",
    "text": "The Remove Elements tab allows to investigate the impact of removing indicators and aggregates from the framework. It addresses the question: how much would the results change if indicator X was not present? This type of analysis can be useful in identifying indicators that could potentially be removed, in order to streamline your indicator framework.\nThe inputs for this tab are very straightforward: you simply select the level at which you want to perform the analysis and click “Run”. This will generate a bar chart which looks something like this:\n\nOn clicking “Run”, the app performs the following analysis, for each indicator (presuming we are working at level 1, the indicator level):\n\nRemove the indicator from the framework\nRecalculate the results following the methodology specified so far in the app\nCompare the results with the indicator excluded, with the results with the indicator included\n\nIn the first step, the indicator is completely removed from the framework and excluded from all data operations. This is subtley different from setting its weight to zero, although typically very similar. In the second step, the app recalculates the results up to the index.\nIn the third step, the new index ranks are compared with the index ranks with all indicators included. Specifically, the difference is calculated as the mean absolute rank change across all units. This gives a single metric of the difference between the two sets of results.\nThis is repeated for every indicator, with replacement (i.e. only one indicator at a time is excluded, but this is repeated for all indicators). Of course, if the level is set at 2 or higher, the process is identical but instead entire aggregate groups are excluded one at a time.\nNow returning to the bar chart: it gives a graphical illustration of the impact of removing each indicator/aggregate. Higher bars indicate that if you were to remove that indicator/aggregate, the results would change more. In the example above, for instance, “income_fit” is clearly an important indicator which, if removed, would significantly change the index rankings. On the other hand, “ict_indiv_using_internet_females” could be removed from the framework without impacting the results very much. Of course, indicators may also have value in other ways, for example in terms of communication, concept, and being of standalone interest.\nAs with the Reweighting tab, this tab is very much a “what if” study, and the analysis here has no impact on the results elsewhere. To actually remove indicators or aggregates from the framework in the final results, you will have to go back to your input Excel sheet and manually remove the indicators. The app does not currently support doing this in-app."
  },
  {
    "objectID": "sensitivity.html#introduction",
    "href": "sensitivity.html#introduction",
    "title": "17  Sensitivity analysis",
    "section": "17.1 Introduction",
    "text": "17.1 Introduction\nSensitivity and uncertainty analysis involve analysing the effects of uncertainties on the results of the composite indicator.\nSensitivity analysis (SA) is however often confused with uncertainty analysis. Uncertainty analysis involves estimating the uncertainty in the outputs of a system (here, the scores and ranks of the composite indicator), given the uncertainties in the inputs (here, methodological decisions, weights, etc.). The results of an uncertainty include for example confidence intervals over the ranks, median ranks, and so on.\nSensitivity analysis is an extra step after uncertainty analysis, and estimates which of the input uncertainties are driving the output uncertainty, and by how much. A rule of thumb, known as the Pareto Principle (or the 80/20 Rule) suggests that often, only a small proportion of the input uncertainties are causing the majority of the output uncertainty. Sensitivity analysis allows us to find which input uncertainties are significant (and therefore perhaps worthy of extra attention), and which are not important.\nIn reality, sensitivity analysis and uncertainty analysis can be performed simultaneously. However in both cases, the main technique is to use Monte Carlo methods. This essentially involves re-calculating the composite indicator many times, each time randomly varying the uncertain variables (assumptions, parameters), in order to estimate the output distributions.\nThe app implements a flexible variance-based global sensitivity analysis approach, which allows almost any assumption to be varied, as long as the distribution of alternative values can be described. Variance-based “sensitivity indices” are estimated using a Monte Carlo design (running the composite indicator many times with a particular combination of input values). This follows the methodology described in this paper."
  },
  {
    "objectID": "sensitivity.html#usage",
    "href": "sensitivity.html#usage",
    "title": "17  Sensitivity analysis",
    "section": "17.2 Usage",
    "text": "17.2 Usage\nThe sensitivity analysis tab implements a global sensitivity analysis as discussed above, giving the user the flexibility to choose which assumptions to treat as uncertain, but with fixed alternatives.\n\n17.2.1 Specification\nThe side panel is where you can specify the basic parameters of the sensitivity analysis. There are four possible assumptions that can be checked:\n\nWhether to impute missing data or not\nWhether to treat outliers or not\nThe choice of aggregation method\nThe values of the weights\n\nThe first two assumptions will be available to select only if you ran those operations in the data operations tabs. In that case:\n\nIf you select the imputation box, the SA will include switching between your selected imputation method (in the imputation tab) and using no imputation.\nIf you select the outlier treatment box, the SA will include switching between outlier treatment or no outlier treatment.\n\nThe aggregation method and weights will always be available to select since these are required to build the composite indicator. For these assumptions:\n\nSelecting the Aggregation method box will include switching between the arithmetic and geometric mean in the SA.\nSelecting the Perturb weights box will test the effect of applying noise to the weights according to the percentage specified in the slider below.\n\nThe noise applied to the weights is uniformly distributed as +/-X%, where X is the value selected in the slider. This noise is applied as follows:\n\nFor indexes with only two levels it is applied to the indicator level\nFor indexes with more than two levels it is applied to all levels above the indicator level\n\nSince sensitivity analysis is a complex topic, these choices are hard-wired into the app for the moment. However, much more flexibility can be achieved by running the sensitivity analysis in R using the COINr package (upon which this app is built). Within the app, the intention is to offer a user-friendly interface which necessarily hides some of the complexity.\nIn any case, to run the sensitivity analysis you must select which assumptions to vary. Then specify the number of replications in the Monte Carlo analysis - here, more leads to a more accurate result but will also take longer. Finally, click “Run” to run the analysis.\n\n\n\n\n\n\nCaution\n\n\n\nYou may receive an error message if you have tried to include aggregation in the sensitivity analysis, and have specified normalisation parameters that lead to zero or negative indicator scores. This is incompatible because the sensitivity analysis will include replications with the geometric mean, which cannot accept zero or negative values. To rectify, either remove the aggregation method from your sensitivity analysis, or change the normalisation method/parameters to result in only positive values.\n\n\n\n\n17.2.2 Results\nThe sensitivity analysis will take some seconds to run, or longer, depending on the number of replications, the complexity of your composite indicator, and the speed of the computer/server running the app. The progress is reported in the progress text box. On completion, a figure should be returned like this:\n\nThis figure plots the ranks of the composite indicator with confidence intervals. The ordering on the x-axis is the “nominal rank”, i.e. the rank without any uncertainty applied. The green dots represent the median ranks observed during the sensitivity analysis - clearly although these roughly correspond to the nominal ranks there are some differences. Finally, the grey vertical lines represent the 90% rank confidence intervals.\nOverall, this plot shows to what extent the ranking is robust to uncertainties. Where grey lines overlap, this means there is some uncertainty about the relative ranking.\nNext, if more than one assumption was selected, the sensitivity analysis plot will be visible:\n\nThis plot shows the relative contribution of each uncertainty selected, to the uncertainty in the rankings. More specifically, it shows the sensitivity indices of each assumption, with bootstrapped confidence intervals. To interpret this, look at the plot on the right side which shows the total sensitivity indices. Each vertical bar represents the estimated range of the sensitivity indices, with the dot being the mean. In the example, the Weights bar is the lowest and has fairly narrow confidence intervals, meaning that the results are relatively insensitive to this assumption. In short, within the range specified for the weights, the impact is relatively small. At the other end, the choice of aggregation shows the highest sensitivity - this means it is the most important assumption, of those tested.\nThe question then arises: what can be done about the uncertainty? The uncertainty in these results stems from the fact that we are not sure which aggregation method is the most suitable, we are not sure the precise values of weights to use, and so on. In some (or many) cases, these uncertainties are simply a fact resulting from the subjective nature of composite indicators, and modelling in general. However, we could attempt to reduce the uncertainty by studying the problem more closely.\nFor example, it is well-known that that in the arithmetic mean, high values of one indicator compensate for low values of another, whereas in the geometric mean the compensation is less. It can be worth examining the concept of your index very carefully to understand whether compensation between indicators is desirable or not. If the choice is clear one way or another, this effectively removes the uncertainty, and the aggregation method can be fixed and removed from the uncertainty analysis.\nFrom the analysis above we might also conclude that:\n\nWeights have relatively little impact, therefore there may not be much value in investing further research in weighting (for example, in an expert survey to elicit weights).\nOutlier treatment also matters relatively little. Potentially one could exclude this step without much impact on the results, to simplify the index for the purposes of communication.\nThe imputation of missing data does seem to matter. It may be worth investing more time in this - for example to see whether more data can be collected, or trying more sophisticated imputation approaches (e.g. outside of the app)."
  },
  {
    "objectID": "sensitivity.html#summary",
    "href": "sensitivity.html#summary",
    "title": "17  Sensitivity analysis",
    "section": "17.3 Summary",
    "text": "17.3 Summary\nIn summary, the sensitivity and uncertainty analyses will:\n\nQuantify the overall uncertainty in ranks\nQuantify how much of the uncertainty in results is caused by each uncertain assumption\n\nIt may also point to ways to reduce uncertainty, but you also have to accept that some uncertainty is inevitable. Importantly, the sensitivity and uncertainty analyses do not account for all uncertainties. For example, there will be additional uncertainties due to missing indicators, in the definition of the conceptual framework and so on."
  }
]